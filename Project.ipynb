{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlfredMoore/music_genre_transformer_classification/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS7DynJDrD-R",
        "outputId": "d8611647-0a34-4619-d474-dc0541378712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\n",
            "Python 3.9.16\n"
          ]
        }
      ],
      "source": [
        "# Googlle Colab Git\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "root_path = \"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\"\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(root_path)\n",
        "# check pwd\n",
        "! pwd\n",
        "# python version\n",
        "! python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# root_path = \"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\"\n",
        "# code_path = os.path.join(root_path,\"music_genre_classification/code\")\n",
        "# metadata_path = os.path.join(root_path,\"music_genre_classification/dataset/fma_metadata\")\n",
        "# fma_medium_path = os.path.join(root_path, \"music_genre_classification/dataset/fma_medium/fma_medium\")\n"
      ],
      "metadata": {
        "id": "tyNtiVZXsHpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg-ExuY1tDq9",
        "outputId": "85ebf23b-47ea-4c52-fe8f-8fad5343c37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'music_genre_classification' already exists and is not an empty directory.\n",
            "fatal: destination path 'fma' already exists and is not an empty directory.\n",
            "dataset  data_test.ipynb  fma  music_genre_classification  Project.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Git Clone\n",
        "os.chdir(root_path)\n",
        "!git clone https://github.com/CVxTz/music_genre_classification.git\n",
        "!git clone https://github.com/mdeff/fma.git\n",
        "!mkdir music_genre_classification/dataset\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6odUP7vtL5U"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt\n",
        "# !pip install tensorflow tqdm scikit_learn\n",
        "#  librosa numpy  pandas matplotlib\n",
        "# !pip show librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGlIN_x-t9tc"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "\n",
        "# !mkdir dataset\n",
        "# !wget -O dataset/fma_metadata.zip -nc https://os.unil.cloud.switch.ch/fma/fma_metadata.zip \n",
        "# !wget -O dataset/fma_medium.zip -nc https://os.unil.cloud.switch.ch/fma/fma_medium.zip\n",
        "# !wget -O dataset/fma_large.zip -nc https://os.unil.cloud.switch.ch/fma/fma_large.zip\n",
        "# !ls dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHKbDEJHt9z6"
      },
      "outputs": [],
      "source": [
        "# unzip\n",
        "# !unzip -n fma_metadata.zip\n",
        "# !ls fma_metadata\n",
        "\n",
        "# failed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGBshxdHt93a",
        "outputId": "59873b8b-37c2-4c12-c04a-f50893dcc6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\n",
            "fma_medium  fma_metadata\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!ls /content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgDTEjsfIhJy"
      },
      "source": [
        "*1*. Prepare Dataset\n",
        "=====\n",
        "\n",
        "  fma_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4apiN5ht98j"
      },
      "outputs": [],
      "source": [
        "os.chdir( os.path.join(root_path,\"music_genre_classification/code\") )\n",
        "import audio_processing\n",
        "import prepare_data\n",
        "# from music_genre_classification.code import audio_processing\n",
        "# from music_genre_classification.code import prepare_data\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import json\n",
        "import numpy as np\n",
        "import ast\n",
        "import sys\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3-c4NSgPU9e"
      },
      "outputs": [],
      "source": [
        "# Prepare Data\n",
        "\n",
        "# load metadata\n",
        "\n",
        "metadata_path = os.path.join(root_path,\"music_genre_classification/dataset/fma_metadata\")\n",
        "# zip_path = os.path.join(dataset_path,\"fma_metadata.zip\")\n",
        "# zf = ZipFile(zip_path)\n",
        "# print(zf.filelist)\n",
        "\n",
        "df = prepare_data.load( os.path.join(metadata_path,\"tracks.csv\") )\n",
        "df2 = pd.read_csv( os.path.join(metadata_path,\"genres.csv\") )\n",
        "\n",
        "out_path = os.path.join(metadata_path,\"tracks_genre.json\")\n",
        "mapping_path = os.path.join(metadata_path,\"mapping.json\")\n",
        "\n",
        "# in_path = \"/media/ml/data_ml/fma_metadata/tracks.csv\"\n",
        "# genres_path = \"/media/ml/data_ml/fma_metadata/genres.csv\"\n",
        "# df = load(\"/media/ml/data_ml/fma_metadata/tracks.csv\")\n",
        "# df2 = pd.read_csv(genres_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRc1zMqxio_U"
      },
      "outputs": [],
      "source": [
        "\n",
        "id_to_title = {k: v for k, v in zip(df2.genre_id.tolist(), df2.title.tolist())}\n",
        "df.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwD4zMiTkIcc"
      },
      "outputs": [],
      "source": [
        "# df.shape\n",
        "# id_to_title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VdPNJemirEB",
        "outputId": "a977fbce-3e30-4cb8-a4fa-0aa5b58c59df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'medium', 'large', 'small'}\n"
          ]
        }
      ],
      "source": [
        "# print(df.head())\n",
        "# print(df.columns.values)\n",
        "print(set(df[(\"set\", \"subset\")].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJEIkvbFmQhD",
        "outputId": "dc034f60-c091-4db8-cc44-6249ca66865c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       track_id     track                    set\n",
            "                genre_top         genres  subset\n",
            "0             2   Hip-Hop           [21]   small\n",
            "1             3   Hip-Hop           [21]  medium\n",
            "2             5   Hip-Hop           [21]   small\n",
            "3            10       Pop           [10]   small\n",
            "4            20       NaN      [76, 103]   large\n",
            "...         ...       ...            ...     ...\n",
            "106569   155316      Rock           [25]   large\n",
            "106570   155317      Rock           [25]   large\n",
            "106571   155318      Rock           [25]   large\n",
            "106572   155319      Rock           [25]   large\n",
            "106573   155320       NaN  [10, 12, 169]   large\n",
            "\n",
            "[106574 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df[df[(\"set\", \"subset\")].isin([\"small\", \"medium\", \"large\"])]\n",
        "print(\n",
        "  df[\n",
        "      [\n",
        "          (\"track_id\", \"\"),\n",
        "          (\"track\", \"genre_top\"),\n",
        "          (\"track\", \"genres\"),\n",
        "          (\"set\", \"subset\"),\n",
        "      ]\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-bEtrpHniVi"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "  k: [id_to_title[a] for a in v]\n",
        "  for k, v in zip(df[(\"track_id\", \"\")].tolist(), df[(\"track\", \"genres\")].tolist())\n",
        "}\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLMvk2z9pEqg"
      },
      "outputs": [],
      "source": [
        "out_path = os.path.join(metadata_path,\"tracks_genre.json\")\n",
        "mapping_path = os.path.join(metadata_path,\"mapping.json\")\n",
        "\n",
        "json.dump(data, open(out_path, \"w\"), indent=4)\n",
        "mapping = {k: i for i, k in enumerate(df2.title.tolist())}\n",
        "json.dump(mapping, open(mapping_path, \"w\"), indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82SqU0ZGPtKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzVetURI001"
      },
      "source": [
        "*2*. Audio Processing\n",
        "======\n",
        "\n",
        "track errors list:\n",
        "\n",
        "001486.mp3, 005574.mp3, 065753.mp3, 108925.mp3, 143992.mp3, 133297.mp3, 098571.mp3, 105247.mp3, 126981.mp3, 080391.mp3, 098559.mp3, 098558.mp3, 098560.mp3, 099134.mp3\n",
        "\n",
        "they should be removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAH1dtX9TmnE"
      },
      "outputs": [],
      "source": [
        "# unzip\n",
        "# !unzip -n /content/drive/MyDrive/Umich_Study/EECS545/Final_Project/dataset/fma_medium.zip -d /content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhnjB3mIwvJo",
        "outputId": "6e05bf35-2f17-4e55-85a1-ecf3246236be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# extracted\n",
            "49972\n",
            "# expected extracted   -14\n",
            "25002 files, 24815301654 bytes uncompressed, 23821584112 bytes compressed:  4.0%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium\")\n",
        "!echo \"# extracted\"\n",
        "!find . -type f | wc -l\n",
        "!echo \"# expected extracted   -14\"\n",
        "!zipinfo /content/drive/MyDrive/Umich_Study/EECS545/Final_Project/dataset/fma_medium.zip | grep files\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\"\n",
        "code_path = os.path.join(root_path,\"music_genre_classification/code\")\n",
        "metadata_path = os.path.join(root_path,\"music_genre_classification/dataset/fma_metadata\")\n",
        "fma_medium_path = os.path.join(root_path, \"music_genre_classification/dataset/fma_medium/fma_medium\")\n",
        "\n",
        "os.chdir(root_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1iv_iYFffgZ",
        "outputId": "1d8a764e-8b56-4901-c20b-469e45ac9ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35G\t/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium/fma_medium\n",
            "35G\t/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium\n"
          ]
        }
      ],
      "source": [
        "# TODO modify\n",
        "!du -h --max-depth=1 /content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QTtZ8TeJGUe"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "\n",
        "from music_genre_classification.code import audio_processing\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from multiprocessing import Pool\n",
        "\n",
        "input_length = 16000 * 30\n",
        "n_mels = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## delete allow_tickle==Flase data\n",
        "# files_transed = sorted(list(glob(fma_medium_path + \"/*/*.npy\")))\n",
        "# for file in files_transed:\n",
        "#   os.remove(file)"
      ],
      "metadata": {
        "id": "oRcOO4mzJQ3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKniKBo5MXUc",
        "outputId": "d198890e-4a9e-4145-8cc9-b56b9c30198f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "# tracks  24985\n",
            "# files_transed 0\n",
            "# remaining tracks  24985\n"
          ]
        }
      ],
      "source": [
        "\n",
        "files = sorted(list(glob(fma_medium_path + \"/*/*.mp3\")))\n",
        "files_transed = sorted(list(glob(fma_medium_path + \"/*/*.npy\")))\n",
        "\n",
        "for i in range(len(files_transed)):\n",
        "  files_transed[i] = files_transed[i].replace(\".npy\",\".mp3\")\n",
        "\n",
        "try:\n",
        "  print(files_transed[0])\n",
        "except:\n",
        "  print(len(files_transed))\n",
        "\n",
        "remained_files = list(set(files) - set(files_transed))\n",
        "\n",
        "print(\"# tracks \",len(files))\n",
        "print(\"# files_transed\",len(files_transed))\n",
        "print(\"# remaining tracks \",len(remained_files))\n",
        "assert len(files)-len(files_transed)==len(remained_files)\n",
        "\n",
        "# p = Pool(8)\n",
        "# for i, _ in tqdm(enumerate(p.imap(audio_processing.save, files))):\n",
        "#   if i % 1000 == 0:\n",
        "#     print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOpsj6pxZjg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f889c457-5d2f-49a2-956d-666edd1dbb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(remained_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5HLERFfYI_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d677043-2105-4774-fcbe-d00f47fe2545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:50, 13.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "963it [02:41, 12.43it/s]/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/code/audio_processing.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=16000)[0]  # , sr=16000\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "1000it [02:46,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2001it [04:45,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3000it [06:41,  9.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3466it [07:37,  5.30it/s]/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/code/audio_processing.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=16000)[0]  # , sr=16000\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "4001it [08:42,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5002it [10:42,  7.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5999it [12:44,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7003it [14:51,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8002it [16:51, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9003it [18:50,  9.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10002it [20:48,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11004it [22:46, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12003it [24:49, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13002it [26:48,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14000it [28:51,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15005it [30:52,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16001it [32:51, 12.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16485it [33:50,  5.55it/s]/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/code/audio_processing.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=16000)[0]  # , sr=16000\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "17003it [34:55, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18000it [36:58,  6.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18271it [37:29, 11.56it/s]/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/code/audio_processing.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=16000)[0]  # , sr=16000\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "18575it [38:06,  9.53it/s]/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/code/audio_processing.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=16000)[0]  # , sr=16000\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "18999it [38:56,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20002it [40:57,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21001it [42:57,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22001it [44:59,  6.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23002it [46:59, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24001it [49:00,  9.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24985it [51:00,  8.16it/s]\n"
          ]
        }
      ],
      "source": [
        "p = Pool(8)\n",
        "for i, _ in tqdm(enumerate(p.imap(audio_processing.save, remained_files))):\n",
        "    if i % 1000 == 0:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXHZyQVIeyHQ"
      },
      "outputs": [],
      "source": [
        "# !pip show librosa numpy scikit_learn numba tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKYq6AcNqHxT"
      },
      "source": [
        "*3*. Pretrain Transformer\n",
        "====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYjObforp2Sj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir( os.path.join(root_path,\"music_genre_classification/code\") )\n",
        "\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from models import transformer_pretrain\n",
        "from prepare_data import get_id_from_path, PretrainGenerator\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project\"\n",
        "code_path = os.path.join(root_path,\"music_genre_classification/code\")\n",
        "metadata_path = os.path.join(root_path,\"music_genre_classification/dataset/fma_metadata\")\n",
        "fma_medium_path = os.path.join(root_path, \"music_genre_classification/dataset/fma_medium/fma_medium\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDiy2w9xtxOs"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "h5_name = \"transformer_pretrain.h5\"\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "id_to_genres = json.load(open( out_path ))\n",
        "id_to_genres = {int(k): v for k, v in id_to_genres.items()}\n",
        "\n",
        "base_path = fma_medium_path     # fma medium dataset\n",
        "files = sorted(list(glob(base_path + \"/*/*.npy\")))\n",
        "files = [x for x in files if id_to_genres[int(get_id_from_path(x))]]\n",
        "labels = [id_to_genres[int(get_id_from_path(x))] for x in files]\n",
        "print(len(labels))\n",
        "\n",
        "samples = list(zip(files, labels))\n",
        "\n",
        "strat = [a[-1] for a in labels]\n",
        "cnt = Counter(strat)\n",
        "strat = [a if cnt[a] > 2 else \"\" for a in strat]\n",
        "\n",
        "train, val = train_test_split(\n",
        "    samples, test_size=0.2, random_state=1337, stratify=strat\n",
        ")\n",
        "\n",
        "model = transformer_pretrain()\n",
        "\n",
        "try:\n",
        "    model.load_weights(h5_name, by_name=True)\n",
        "    print(\"Weights Loaded\")\n",
        "except:\n",
        "    print(\"Could not load weights\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    h5_name,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "reduce_o_p = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", patience=20, min_lr=1e-7, mode=\"min\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    model.load_weights(h5_name)\n",
        "except:\n",
        "    print(\"Could not load weights\")\n",
        "\n",
        "model.fit_generator(\n",
        "    PretrainGenerator(train, batch_size=batch_size),\n",
        "    validation_data=PretrainGenerator(val, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpoint, reduce_o_p],\n",
        "    use_multiprocessing=True,\n",
        "    workers=12,\n",
        "    verbose=2,\n",
        "    max_queue_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJcD5d77zhqA"
      },
      "source": [
        "*4*. Transformer Claasifier\n",
        "====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZgaEdEJznaU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from models import transformer_classifier\n",
        "from prepare_data import get_id_from_path, DataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTLMGT7t0ayL"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "h5_name = \"transformer.h5\"\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "CLASS_MAPPING = json.load(open( mapping_path ))\n",
        "id_to_genres = json.load(open( out_path ))\n",
        "id_to_genres = {int(k): v for k, v in id_to_genres.items()}\n",
        "\n",
        "base_path = fma_medium_path\n",
        "files = sorted(list(glob(base_path + \"/*/*.npy\")))\n",
        "files = [x for x in files if id_to_genres[int(get_id_from_path(x))]]\n",
        "labels = [id_to_genres[int(get_id_from_path(x))] for x in files]\n",
        "print(len(labels))\n",
        "\n",
        "samples = list(zip(files, labels))\n",
        "\n",
        "strat = [a[-1] for a in labels]\n",
        "cnt = Counter(strat)\n",
        "strat = [a if cnt[a] > 2 else \"\" for a in strat]\n",
        "\n",
        "train, val = train_test_split(\n",
        "    samples, test_size=0.2, random_state=1337, stratify=strat\n",
        ")\n",
        "\n",
        "model = transformer_classifier(n_classes=len(CLASS_MAPPING))\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    h5_name,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "reduce_o_p = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", patience=20, min_lr=1e-7, mode=\"min\"\n",
        ")\n",
        "\n",
        "model.fit_generator(\n",
        "    DataGenerator(train, batch_size=batch_size, class_mapping=CLASS_MAPPING),\n",
        "    validation_data=DataGenerator(\n",
        "        val, batch_size=batch_size, class_mapping=CLASS_MAPPING\n",
        "    ),\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpoint, reduce_o_p],\n",
        "    use_multiprocessing=True,\n",
        "    workers=12,\n",
        "    verbose=2,\n",
        "    max_queue_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N0MWgOj7EYg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "a = np.load(\"/content/drive/MyDrive/Umich_Study/EECS545/Final_Project/music_genre_classification/dataset/fma_medium/fma_medium/000/000002.npy\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}